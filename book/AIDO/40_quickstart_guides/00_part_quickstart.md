# Quickstart guides {#part:aido-quickstart}


## Protocol

### Deployment technique

We will use Docker containers to package, deploy, and run the applications on the physical Duckietown platform as well as on the cloud for simulation. Base Docker container images will be provided and distributed via [Docker HUB][dockerhub].

[dockerhub]: https://hub.docker.com/r/duckietown/

A *Master* server will be used to collect and queue all submitted programs. The *simulation evaluation agents* will execute each queued program as they become available. Submissions that pass the simulation environment will be queued for execution in the robotariums.

<!-- <div figure-id="fig:dockerflow">
\input{dockerflow.tex}
<figcaption>Submission, Deployment, and Execution Flow
</figcaption>
</div> -->

Access to Robotarium will be granted once submitted code passes the simulation stage of the competition.


For validation of submitted code and evaluation for finals at NIPS a surprise environment will be employed. This is to discourage overfitting to any particular Duckietown.


### Submission of entries

Upon enrollment in the competition (https://www2.duckietown.org/nips-2018-competition/register-for-nips-2018), participants can submit their code in the form of a docker container to a task or module of the AI-DO. Scripts will be provided for creating the container image in a conforming way.

The system will schedule to run the code on the cloud on the challenges selected by the user, and, if simulations pass, on the robotariums.

Participants can submit entries as many times as they would like. Access control policies are to be implemented, should certain participants monopolize the computational and physical resources available.

Participants are required to open source their solutions source code. If auxiliary training data are used to train the models, that data must be made available.

Submitted code will be evaluated in simulation and if sufficient on physical robotariums. Scores and logs generated with submitted code will be made available.

How to get started: http://docs.duckietown.org/AIDO/out/aido_quickstart.html.

### Simulators

Simulation code will be available as open source for everybody to use on computers that they control.

Amazon AWS will make available cloud resources to run the cloud simulations and the cloud learning. The access to these resources might be rationed if the utilization exceeds the projections.

### Robotarium test and validation

If there are $n$ robotariums available, $n-1$ robotariums can be used for training and testing, while 1 robotarium is used for validation.

When an experiment is run in a training/testing robotarium, the participants receive, in addition to the score, detailed feedback, including logs, telemetry, videos from external cameras, etc.

The sensory data generated by the robots is continuously recorded and becomes available immediately to the entire community.

When an experiment is run in a validation robotarium, the only output to the user is the test score and minimal statistics (number of collisions, number of rule violations, etc.)

### Leaderboards

After each run in a robotarium, the participants can see the metrics statistics in the competition website.

Leaderboards are reset at the beginning of October 2018.
